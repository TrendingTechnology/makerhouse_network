# Taken with edits from https://github.com/cablespaghetti/k3s-monitoring

# 2021-06-25: This disables a bunch of stuff which would be otherwise useful if downtime
# was a bigger issue than the amount of storage we're overrunning.
defaultRules:
  create: false
kubelet:
  enabled: false
coreDns:
  enabled: false
kubeDns:
  enabled: false
kubeProxy:
  enabled: false
kubeStateMetrics:
  enabled: false
kubeApiServer:
  enabled: false

# Disable etcd monitoring. See https://github.com/cablespaghetti/k3s-monitoring/issues/4
kubeEtcd:
  enabled: false

# Disable kube-controller-manager and kube-scheduler monitoring. See https://github.com/cablespaghetti/k3s-monitoring/issues/2
kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false

alertmanager:
  config:
    # global:
    #   smtp_from: smartin015@gmail.com
    #  smtp_smarthost: smtp.gmail.com:587
    #  smtp_auth_username: you@gmail.com
    #  smtp_auth_password: yourapppassword # https://support.google.com/mail/answer/185833?hl=en-GB
    #  smtp_auth_identity: you@gmail.com
    route:
      group_by: ['job']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 1h
      receiver: email
      routes:
      - match:
          alertname: Watchdog
        receiver: 'null'
      - match:
          alertname: CPUThrottlingHigh
        receiver: 'null'
      - match:
          alertname: KubeMemoryOvercommit
        receiver: 'null'
      - match:
          alertname: KubeCPUOvercommit
        receiver: 'null'
      - match:
          alertname: KubeletTooManyPods
        receiver: 'null'

    receivers:
    - name: 'null'
    - name: email
      email_configs:
      - send_resolved: true
        to: smartin015@gmail.com

    # Inhibition rules allow to mute a set of alerts given that another alert is firing.
    # We use this to mute any warning-level notifications if the same alert is already critical.
    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      # Apply inhibition if the alertname is the same.
      equal: ['alertname', 'namespace']

  alertmanagerSpec:
    storage:
      volumeClaimTemplate:
        metadata:
          name: alertmanager
        spec:
          accessModes: ["ReadWriteOnce"]
          storageClassName: longhorn
          resources:
            requests:
              storage: 1Gi

prometheus:
  service:
    type: LoadBalancer
    loadBalancerIP: "192.168.0.6"
  serviceMonitor:
    selfMonitor: false
  prometheusSpec:
    # https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/additional-scrape-config.md
    enableAdminAPI: true # Allow deleting metrics
    additionalScrapeConfigsSecret:
      enabled: true
      name: additional-scrape-configs
      key: prometheus-additional.yaml
    retention: 365d
    # 2021-10-31: This contains a snapshot of the generated container config, plus the "nasbackup" container added in for periodically snapshotting prometheus data and sending it to the NAS
    #containers:
    #- name: nasbackup                                                                                                                       
    #  image: repository.mkr.house:443:/nas-backup
    #  imagePullPolicy: Always
    #  volumeMounts:                                                             
    #  - mountPath: /prometheus                       
    #    name: prometheus
    #    subPath: prometheus-db           
    storageSpec:
      volumeClaimTemplate:
        metadata:
          name: prometheus
        spec:
          accessModes: ["ReadWriteOnce"] 
          storageClassName: longhorn
          resources:
            requests:
              storage: 50Gi

grafana:
  plugins:
    - grafana-piechart-panel
  service:
    type: LoadBalancer
    loadBalancerIP: "192.168.0.7"
  serviceMonitor: 
    selfMonitor: false

nodeExporter:
  enabled: false

prometheusOperator:
  serviceMonitor: 
    selfMonitor: false

kube-state-metrics:

